{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a453602e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8ccdf29c",
   "metadata": {},
   "outputs": [],
   "source": [
    "home = os.path.expanduser( '~' )\n",
    "with open('../train.pickle', 'rb') as f:\n",
    "    train = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "755de83e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame.from_dict(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7d127cc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def helper_regex(string, pat):\n",
    "    string = str(string)\n",
    "    if pat == 'm2':\n",
    "        pattern = r'\\b(\\d+(\\.\\d+)?) m2\\b'\n",
    "    elif pat == 'bedrooms':\n",
    "        pattern = r'\\b(\\d+) hab\\b'\n",
    "    else:\n",
    "        pattern = r'\\b(\\d+) bañ(o|os)\\b'\n",
    "    match = re.search(pattern, string)\n",
    "    return float(match.group(1)) if match else np.nan\n",
    "\n",
    "def clean_df(df, valid_df=None, valid=False):\n",
    "    df['m2'] = df.features.apply(helper_regex, args=('m2',))\n",
    "    df['bedrooms'] = df.features.apply(helper_regex, args=('bedrooms',))\n",
    "    df['bathrooms'] = df.features.apply(helper_regex, args=('bathrooms',))\n",
    "    df['m2'].fillna(-1, inplace=True)\n",
    "    df['bedrooms'].fillna(-1, inplace=True)\n",
    "    df['bathrooms'].fillna(-1, inplace=True)\n",
    "    if valid:\n",
    "        valid_df['m2'] = valid_df.features.apply(helper_regex, args=('m2',))\n",
    "        valid_df['bedrooms'] = valid_df.features.apply(helper_regex, args=('bedrooms',))\n",
    "        valid_df['bathrooms'] = valid_df.features.apply(helper_regex, args=('bathrooms',))\n",
    "        valid_df['m2'].fillna(-1, inplace=True)\n",
    "        valid_df['bedrooms'].fillna(-1, inplace=True)\n",
    "        valid_df['bathrooms'].fillna(-1, inplace=True)\n",
    "        return valid_df[['m2','bedrooms','bathrooms','loc_string','type','desc']]\n",
    "    return df[['m2','bedrooms','bathrooms','loc_string','type','desc']], df['price'].str.split(' ', expand=True)[0].astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c0244891",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean, target = clean_df(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bac080da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>m2</th>\n",
       "      <th>bedrooms</th>\n",
       "      <th>bathrooms</th>\n",
       "      <th>loc_string</th>\n",
       "      <th>type</th>\n",
       "      <th>desc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>85.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Barcelona - Sant Antoni</td>\n",
       "      <td>FLAT</td>\n",
       "      <td>Piso en última planta a reformar en calle Tall...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>65.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Barcelona - Dreta de l´Eixample</td>\n",
       "      <td>FLAT</td>\n",
       "      <td>Ubicado en la zona del Camp de l’Arpa, cerca d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>77.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Barcelona - Dreta de l´Eixample</td>\n",
       "      <td>FLAT</td>\n",
       "      <td>En pleno centro de Barcelona, justo al lado de...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>96.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Barcelona - Sant Antoni</td>\n",
       "      <td>FLAT</td>\n",
       "      <td>Vivienda espaciosa en Sant Antoni, cerca de Pl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>84.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Barcelona - Sagrada Família</td>\n",
       "      <td>FLAT</td>\n",
       "      <td>En el corazón de Barcelona, en una hermosa fin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>861</th>\n",
       "      <td>115.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Barcelona - Navas</td>\n",
       "      <td>FLAT</td>\n",
       "      <td>HANNAN-PIPER Real Estate les presenta, en excl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>862</th>\n",
       "      <td>82.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Barcelona - Navas</td>\n",
       "      <td>FLAT</td>\n",
       "      <td>¡ OPORTUNIDAD !\\n\\nLa Casa Agency vende: Vivie...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>863</th>\n",
       "      <td>79.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Barcelona - Navas</td>\n",
       "      <td>FLAT</td>\n",
       "      <td>Piso totalmente REFORMADO y a ESTRENAR, con MU...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>864</th>\n",
       "      <td>63.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Barcelona - Navas</td>\n",
       "      <td>FLAT</td>\n",
       "      <td>Presentamos la oportunidad de comprar un bonit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>865</th>\n",
       "      <td>80.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Barcelona - Navas</td>\n",
       "      <td>FLAT</td>\n",
       "      <td>Piso de 80 metros totalmente reformado en Sagr...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>866 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        m2  bedrooms  bathrooms                       loc_string  type  \\\n",
       "0     85.0       2.0        1.0          Barcelona - Sant Antoni  FLAT   \n",
       "1     65.0       2.0        1.0  Barcelona - Dreta de l´Eixample  FLAT   \n",
       "2     77.0       2.0        1.0  Barcelona - Dreta de l´Eixample  FLAT   \n",
       "3     96.0       3.0        2.0          Barcelona - Sant Antoni  FLAT   \n",
       "4     84.0       2.0        1.0      Barcelona - Sagrada Família  FLAT   \n",
       "..     ...       ...        ...                              ...   ...   \n",
       "861  115.0       3.0        1.0                Barcelona - Navas  FLAT   \n",
       "862   82.0       3.0        1.0                Barcelona - Navas  FLAT   \n",
       "863   79.0       4.0        2.0                Barcelona - Navas  FLAT   \n",
       "864   63.0       1.0        1.0                Barcelona - Navas  FLAT   \n",
       "865   80.0       2.0        1.0                Barcelona - Navas  FLAT   \n",
       "\n",
       "                                                  desc  \n",
       "0    Piso en última planta a reformar en calle Tall...  \n",
       "1    Ubicado en la zona del Camp de l’Arpa, cerca d...  \n",
       "2    En pleno centro de Barcelona, justo al lado de...  \n",
       "3    Vivienda espaciosa en Sant Antoni, cerca de Pl...  \n",
       "4    En el corazón de Barcelona, en una hermosa fin...  \n",
       "..                                                 ...  \n",
       "861  HANNAN-PIPER Real Estate les presenta, en excl...  \n",
       "862  ¡ OPORTUNIDAD !\\n\\nLa Casa Agency vende: Vivie...  \n",
       "863  Piso totalmente REFORMADO y a ESTRENAR, con MU...  \n",
       "864  Presentamos la oportunidad de comprar un bonit...  \n",
       "865  Piso de 80 metros totalmente reformado en Sagr...  \n",
       "\n",
       "[866 rows x 6 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "620dd8e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_dummies(df):\n",
    "    return pd.get_dummies(df, columns=['loc_string','type'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f39a892b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean = convert_dummies(df_clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "03904401",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModel, AutoTokenizer\n",
    "model_name = \"lxyuan/distilbert-base-multilingual-cased-sentiments-student\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model1 = AutoModel.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b86fc55d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "def generate_embeddings(text):\n",
    "    tokenized_text = tokenizer(text, padding=True, truncation=True, return_tensors=\"pt\")\n",
    "    with torch.no_grad():\n",
    "        outputs = model1(**tokenized_text)\n",
    "    embeddings = outputs.last_hidden_state.mean(dim=1)\n",
    "    return embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7cc92db4",
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = df_clean['desc'].apply(generate_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "38f02b91",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>StandardScaler()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">StandardScaler</label><div class=\"sk-toggleable__content\"><pre>StandardScaler()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "StandardScaler()"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "X_numeric = df_clean[['m2','bedrooms','bathrooms']]\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X_numeric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "773cf0e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_scale = scaler.transform(X_numeric)\n",
    "x_loc = df_clean[[col for col in df_clean.columns if 'loc_string' in col or 'type' in col]].astype(float).to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "750f15b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Train-test split\n",
    "X = torch.cat((torch.from_numpy(x_scale),torch.from_numpy(x_loc),torch.cat(embeddings.tolist())),1).float()\n",
    "y = torch.from_numpy(target.to_numpy())\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "0b998f17",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "# Define PyTorch model\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.fc1 = nn.Linear(796, 128) \n",
    "        self.relu = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(128, 1)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = x.float()\n",
    "        x = self.fc1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.fc2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "663da7ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "# Initialize model, loss function, and optimizer\n",
    "model2 = Net()\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(model2.parameters(), lr=0.001)\n",
    "# optimizer = optim.Adam(model2.parameters(), lr=0.1) \n",
    "# optimizer = optim.Adam(model2.parameters(), lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "592b3ccc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import r2_score\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "def val_metric(model, valid_dl):\n",
    "    model.eval()\n",
    "    losses = []\n",
    "    y_hats = []\n",
    "    ys = []\n",
    "    for x, y in valid_dl:\n",
    "        y_hat = model(x.float())\n",
    "        loss = F.mse_loss(y_hat, y.float().unsqueeze(1))\n",
    "        y_hats.append(y_hat.detach().numpy())\n",
    "        ys.append(y.numpy())\n",
    "        losses.append(loss.item())\n",
    "    \n",
    "    ys = np.concatenate(ys)\n",
    "    y_hats = np.concatenate(y_hats)\n",
    "    return np.mean(losses), r2_score(ys, y_hats)\n",
    "\n",
    "def train_loop(model, train_dl, valid_dl, optimizer, epochs):\n",
    "    losses = []\n",
    "    for i in range(epochs):\n",
    "        model.train()\n",
    "        for x, y in train_dl:\n",
    "            y_hat = model(x.float())\n",
    "            loss = F.mse_loss(y_hat, y.float().unsqueeze(1))\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            losses.append(loss.item())\n",
    "        \n",
    "        train_loss = np.mean(losses)\n",
    "        valid_loss, valid_auc = val_metric(model, valid_dl)\n",
    "        if i%50 == 0:\n",
    "            print(\"train loss %.3f valid loss %.3f R2 %.3f\" % \n",
    "                  (train_loss, valid_loss, valid_auc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "72e8d855",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "# Prepare DataLoader\n",
    "train_dataset = TensorDataset(X_train, y_train)\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "valid_dataset = TensorDataset(X_test, y_test)\n",
    "valid_loader = DataLoader(valid_dataset, batch_size=64, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "db99b452",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss 122658.525 valid loss 116732.398 R2 -19.949\n",
      "train loss 19485.865 valid loss 4544.778 R2 0.215\n",
      "train loss 11819.015 valid loss 3528.908 R2 0.391\n",
      "train loss 8991.517 valid loss 2965.841 R2 0.486\n",
      "train loss 7462.532 valid loss 2661.147 R2 0.537\n",
      "train loss 6482.899 valid loss 2486.100 R2 0.564\n",
      "train loss 5792.862 valid loss 2449.183 R2 0.568\n",
      "train loss 5279.049 valid loss 2421.530 R2 0.570\n"
     ]
    }
   ],
   "source": [
    "train_loop(model2, train_loader, valid_loader, optimizer, epochs=400)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "761a60ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# hyperparam search results\n",
    "\n",
    "# EPOCHS:\n",
    "# 400 selected as close to optimal\n",
    "# train loss 123146.778 valid loss 117264.086 R2 -20.045\n",
    "# train loss 19529.198 valid loss 4557.824 R2 0.213\n",
    "# train loss 11841.983 valid loss 3529.190 R2 0.390\n",
    "# train loss 9006.410 valid loss 2975.565 R2 0.485\n",
    "# train loss 7472.548 valid loss 2658.420 R2 0.537\n",
    "# train loss 6489.845 valid loss 2497.027 R2 0.562\n",
    "# train loss 5798.061 valid loss 2437.986 R2 0.569\n",
    "# train loss 5282.371 valid loss 2423.802 R2 0.569\n",
    "# train loss 4883.059 valid loss 2446.239 R2 0.563\n",
    "# train loss 4563.317 valid loss 2495.837 R2 0.553\n",
    "# train loss 4301.058 valid loss 2551.174 R2 0.543\n",
    "# train loss 4081.709 valid loss 2539.044 R2 0.544\n",
    "# train loss 3894.907 valid loss 2616.675 R2 0.530\n",
    "# train loss 3733.773 valid loss 2602.759 R2 0.531\n",
    "# train loss 3592.785 valid loss 2636.798 R2 0.525\n",
    "# train loss 3468.017 valid loss 2728.841 R2 0.509\n",
    "\n",
    "# Learning rate: 0.01\n",
    "# train loss 93144.997 valid loss 37365.315 R2 -5.702\n",
    "# train loss 5396.729 valid loss 2490.490 R2 0.559\n",
    "# train loss 3732.610 valid loss 2454.221 R2 0.560\n",
    "# train loss 3077.187 valid loss 2524.390 R2 0.547\n",
    "# train loss 2699.771 valid loss 2494.183 R2 0.552\n",
    "# train loss 2431.254 valid loss 2577.741 R2 0.536\n",
    "# train loss 2232.138 valid loss 2651.122 R2 0.523\n",
    "# train loss 2063.081 valid loss 2694.784 R2 0.516\n",
    "\n",
    "# Learning rate 0.1\n",
    "# train loss 29403.618 valid loss 4523.429 R2 0.221\n",
    "# train loss 3030.731 valid loss 2756.205 R2 0.512\n",
    "# train loss 2208.557 valid loss 3329.776 R2 0.401\n",
    "# train loss 1681.966 valid loss 4040.415 R2 0.281\n",
    "# train loss 1354.280 valid loss 4537.712 R2 0.191\n",
    "# train loss 1133.233 valid loss 4730.176 R2 0.153\n",
    "# train loss 969.536 valid loss 4680.087 R2 0.162\n",
    "# train loss 854.781 valid loss 4665.918 R2 0.171"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "04815f6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "home = os.path.expanduser( '~' )\n",
    "with open(home + '/data/test_kaggle.pickle', 'rb') as f:\n",
    "    test = pickle.load(f) \n",
    "df_test = pd.DataFrame.from_dict(test)\n",
    "test_clean = clean_df(df, df_test, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "20813d5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_embed = df_test['desc'].apply(generate_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "bf0c9b7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = convert_dummies(test_clean)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "aa45186c",
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in df_clean.columns:\n",
    "    if ('loc_string' in col) or 'type_' in col:\n",
    "        if col not in test.columns:\n",
    "            test[col] = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "e1997122",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test_scale = scaler.transform(test[['m2','bedrooms','bathrooms']])\n",
    "x_test_loc = test[[col for col in df_clean.columns if ('loc_string' in col) or 'type_' in col]].astype(float).to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "e03fe70f",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = torch.cat((torch.from_numpy(x_test_scale),torch.from_numpy(x_test_loc),torch.cat(test_embed.tolist())),1).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "46b95dc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "yhat = model2(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "dbd1f334",
   "metadata": {},
   "outputs": [],
   "source": [
    "depth = [i for i in range(1,10)]\n",
    "eta = [0.03,0.04,0.05,0.06,0.07,0.08]\n",
    "params = []\n",
    "r2 = []\n",
    "for i in depth:\n",
    "    for j in eta:\n",
    "        model = XGBRegressor(max_depth=i, eta=j)\n",
    "        # fit model\n",
    "        model.fit(X_train, y_train)\n",
    "        yhat = model.predict(X_test)\n",
    "        params.append((i,j))\n",
    "        r2.append(r2_score(y_test, yhat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "5ed8f924",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>params</th>\n",
       "      <th>r2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>(1, 0.03)</td>\n",
       "      <td>0.481014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>(1, 0.04)</td>\n",
       "      <td>0.512584</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>(1, 0.05)</td>\n",
       "      <td>0.531326</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>(1, 0.06)</td>\n",
       "      <td>0.542734</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>(1, 0.07)</td>\n",
       "      <td>0.550384</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>(1, 0.08)</td>\n",
       "      <td>0.556924</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>(2, 0.03)</td>\n",
       "      <td>0.531595</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>(2, 0.04)</td>\n",
       "      <td>0.547445</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>(2, 0.05)</td>\n",
       "      <td>0.548821</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>(2, 0.06)</td>\n",
       "      <td>0.561329</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>(2, 0.07)</td>\n",
       "      <td>0.554196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>(2, 0.08)</td>\n",
       "      <td>0.573669</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>(3, 0.03)</td>\n",
       "      <td>0.546442</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>(3, 0.04)</td>\n",
       "      <td>0.558765</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>(3, 0.05)</td>\n",
       "      <td>0.567246</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>(3, 0.06)</td>\n",
       "      <td>0.567322</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>(3, 0.07)</td>\n",
       "      <td>0.564920</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>(3, 0.08)</td>\n",
       "      <td>0.555957</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>(4, 0.03)</td>\n",
       "      <td>0.558003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>(4, 0.04)</td>\n",
       "      <td>0.550205</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>(4, 0.05)</td>\n",
       "      <td>0.554535</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>(4, 0.06)</td>\n",
       "      <td>0.547267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>(4, 0.07)</td>\n",
       "      <td>0.542687</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>(4, 0.08)</td>\n",
       "      <td>0.572246</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>(5, 0.03)</td>\n",
       "      <td>0.525677</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>(5, 0.04)</td>\n",
       "      <td>0.535860</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>(5, 0.05)</td>\n",
       "      <td>0.524915</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>(5, 0.06)</td>\n",
       "      <td>0.538703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>(5, 0.07)</td>\n",
       "      <td>0.563140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>(5, 0.08)</td>\n",
       "      <td>0.535144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>(6, 0.03)</td>\n",
       "      <td>0.508085</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>(6, 0.04)</td>\n",
       "      <td>0.499782</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>(6, 0.05)</td>\n",
       "      <td>0.514745</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>(6, 0.06)</td>\n",
       "      <td>0.512480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>(6, 0.07)</td>\n",
       "      <td>0.507639</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>(6, 0.08)</td>\n",
       "      <td>0.524519</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>(7, 0.03)</td>\n",
       "      <td>0.474312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>(7, 0.04)</td>\n",
       "      <td>0.494079</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>(7, 0.05)</td>\n",
       "      <td>0.491098</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>(7, 0.06)</td>\n",
       "      <td>0.489817</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>(7, 0.07)</td>\n",
       "      <td>0.492719</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>(7, 0.08)</td>\n",
       "      <td>0.488862</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>(8, 0.03)</td>\n",
       "      <td>0.484935</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>(8, 0.04)</td>\n",
       "      <td>0.488740</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>(8, 0.05)</td>\n",
       "      <td>0.494996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>(8, 0.06)</td>\n",
       "      <td>0.478583</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>(8, 0.07)</td>\n",
       "      <td>0.474798</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>(8, 0.08)</td>\n",
       "      <td>0.497888</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>(9, 0.03)</td>\n",
       "      <td>0.491937</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>(9, 0.04)</td>\n",
       "      <td>0.482522</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>(9, 0.05)</td>\n",
       "      <td>0.481014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>(9, 0.06)</td>\n",
       "      <td>0.492577</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>(9, 0.07)</td>\n",
       "      <td>0.504739</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>(9, 0.08)</td>\n",
       "      <td>0.487293</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       params        r2\n",
       "0   (1, 0.03)  0.481014\n",
       "1   (1, 0.04)  0.512584\n",
       "2   (1, 0.05)  0.531326\n",
       "3   (1, 0.06)  0.542734\n",
       "4   (1, 0.07)  0.550384\n",
       "5   (1, 0.08)  0.556924\n",
       "6   (2, 0.03)  0.531595\n",
       "7   (2, 0.04)  0.547445\n",
       "8   (2, 0.05)  0.548821\n",
       "9   (2, 0.06)  0.561329\n",
       "10  (2, 0.07)  0.554196\n",
       "11  (2, 0.08)  0.573669\n",
       "12  (3, 0.03)  0.546442\n",
       "13  (3, 0.04)  0.558765\n",
       "14  (3, 0.05)  0.567246\n",
       "15  (3, 0.06)  0.567322\n",
       "16  (3, 0.07)  0.564920\n",
       "17  (3, 0.08)  0.555957\n",
       "18  (4, 0.03)  0.558003\n",
       "19  (4, 0.04)  0.550205\n",
       "20  (4, 0.05)  0.554535\n",
       "21  (4, 0.06)  0.547267\n",
       "22  (4, 0.07)  0.542687\n",
       "23  (4, 0.08)  0.572246\n",
       "24  (5, 0.03)  0.525677\n",
       "25  (5, 0.04)  0.535860\n",
       "26  (5, 0.05)  0.524915\n",
       "27  (5, 0.06)  0.538703\n",
       "28  (5, 0.07)  0.563140\n",
       "29  (5, 0.08)  0.535144\n",
       "30  (6, 0.03)  0.508085\n",
       "31  (6, 0.04)  0.499782\n",
       "32  (6, 0.05)  0.514745\n",
       "33  (6, 0.06)  0.512480\n",
       "34  (6, 0.07)  0.507639\n",
       "35  (6, 0.08)  0.524519\n",
       "36  (7, 0.03)  0.474312\n",
       "37  (7, 0.04)  0.494079\n",
       "38  (7, 0.05)  0.491098\n",
       "39  (7, 0.06)  0.489817\n",
       "40  (7, 0.07)  0.492719\n",
       "41  (7, 0.08)  0.488862\n",
       "42  (8, 0.03)  0.484935\n",
       "43  (8, 0.04)  0.488740\n",
       "44  (8, 0.05)  0.494996\n",
       "45  (8, 0.06)  0.478583\n",
       "46  (8, 0.07)  0.474798\n",
       "47  (8, 0.08)  0.497888\n",
       "48  (9, 0.03)  0.491937\n",
       "49  (9, 0.04)  0.482522\n",
       "50  (9, 0.05)  0.481014\n",
       "51  (9, 0.06)  0.492577\n",
       "52  (9, 0.07)  0.504739\n",
       "53  (9, 0.08)  0.487293"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb = pd.DataFrame(list(zip(params, r2)), columns =['params', 'r2'])\n",
    "xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "45cd357a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-5 {color: black;}#sk-container-id-5 pre{padding: 0;}#sk-container-id-5 div.sk-toggleable {background-color: white;}#sk-container-id-5 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-5 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-5 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-5 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-5 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-5 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-5 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-5 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-5 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-5 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-5 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-5 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-5 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-5 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-5 div.sk-item {position: relative;z-index: 1;}#sk-container-id-5 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-5 div.sk-item::before, #sk-container-id-5 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-5 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-5 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-5 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-5 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-5 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-5 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-5 div.sk-label-container {text-align: center;}#sk-container-id-5 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-5 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-5\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>XGBRegressor(base_score=None, booster=None, callbacks=None,\n",
       "             colsample_bylevel=None, colsample_bynode=None,\n",
       "             colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
       "             enable_categorical=False, eta=0.08, eval_metric=None,\n",
       "             feature_types=None, gamma=None, grow_policy=None,\n",
       "             importance_type=None, interaction_constraints=None,\n",
       "             learning_rate=None, max_bin=None, max_cat_threshold=None,\n",
       "             max_cat_to_onehot=None, max_delta_step=None, max_depth=4,\n",
       "             max_leaves=None, min_child_weight=None, missing=nan,\n",
       "             monotone_constraints=None, multi_strategy=None, n_estimators=None,\n",
       "             n_jobs=None, num_parallel_tree=None, ...)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" checked><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">XGBRegressor</label><div class=\"sk-toggleable__content\"><pre>XGBRegressor(base_score=None, booster=None, callbacks=None,\n",
       "             colsample_bylevel=None, colsample_bynode=None,\n",
       "             colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
       "             enable_categorical=False, eta=0.08, eval_metric=None,\n",
       "             feature_types=None, gamma=None, grow_policy=None,\n",
       "             importance_type=None, interaction_constraints=None,\n",
       "             learning_rate=None, max_bin=None, max_cat_threshold=None,\n",
       "             max_cat_to_onehot=None, max_delta_step=None, max_depth=4,\n",
       "             max_leaves=None, min_child_weight=None, missing=nan,\n",
       "             monotone_constraints=None, multi_strategy=None, n_estimators=None,\n",
       "             n_jobs=None, num_parallel_tree=None, ...)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "XGBRegressor(base_score=None, booster=None, callbacks=None,\n",
       "             colsample_bylevel=None, colsample_bynode=None,\n",
       "             colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
       "             enable_categorical=False, eta=0.08, eval_metric=None,\n",
       "             feature_types=None, gamma=None, grow_policy=None,\n",
       "             importance_type=None, interaction_constraints=None,\n",
       "             learning_rate=None, max_bin=None, max_cat_threshold=None,\n",
       "             max_cat_to_onehot=None, max_delta_step=None, max_depth=4,\n",
       "             max_leaves=None, min_child_weight=None, missing=nan,\n",
       "             monotone_constraints=None, multi_strategy=None, n_estimators=None,\n",
       "             n_jobs=None, num_parallel_tree=None, ...)"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from xgboost import XGBRegressor\n",
    "model = XGBRegressor(max_depth=4, eta=0.08)\n",
    "# fit model\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "4242ad35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0 1.0 0.5722461616302965\n",
      "0.1 0.9 0.5874523222289074\n",
      "0.2 0.8 0.5990462410810272\n",
      "0.3 0.7 0.6070279181866559\n",
      "0.4 0.6 0.6113973535457935\n",
      "0.5 0.5 0.6121545471584398\n",
      "0.6 0.4 0.609299499024595\n",
      "0.7 0.30000000000000004 0.6028322091442591\n",
      "0.8 0.19999999999999996 0.5927526775174319\n",
      "0.9 0.09999999999999998 0.5790609041441137\n",
      "1.0 0.0 0.5617568890243043\n"
     ]
    }
   ],
   "source": [
    "for i in range(11):\n",
    "    w1 = i/10\n",
    "    w2 = 1-w1\n",
    "    y_pred = np.average( np.array([ model2(X_test).detach().numpy().flatten(), model.predict(X_test) ]), weights = [w1,w2], axis=0 )\n",
    "    print(w1, w2, r2_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "339afe1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "p1 = torch.reshape(torch.from_numpy(model.predict(X_train)), (-1,1))\n",
    "p2 = model2(X_train)\n",
    "t1 = torch.reshape(torch.from_numpy(model.predict(X_test)), (-1,1))\n",
    "t2 = model2(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "813d89dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "xtrain_mod = torch.cat((X_train, p1, p2), axis=1)\n",
    "xtest_mod = torch.cat((X_test, t1, t2), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "55815890",
   "metadata": {},
   "outputs": [],
   "source": [
    "depth = [i for i in range(1,10)]\n",
    "eta = [0.03,0.04,0.05,0.06,0.07,0.08]\n",
    "params = []\n",
    "r2 = []\n",
    "for i in depth:\n",
    "    for j in eta:\n",
    "        model3 = XGBRegressor(max_depth=i, eta=j)\n",
    "        # fit model\n",
    "        model3.fit(xtrain_mod.detach(), y_train)\n",
    "        yhat = model3.predict(xtest_mod.detach())\n",
    "        params.append((i,j))\n",
    "        r2.append(r2_score(y_test, yhat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "9285edbc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>params</th>\n",
       "      <th>r2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>(1, 0.03)</td>\n",
       "      <td>0.523491</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>(1, 0.04)</td>\n",
       "      <td>0.523231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>(1, 0.05)</td>\n",
       "      <td>0.520601</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>(1, 0.06)</td>\n",
       "      <td>0.518823</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>(1, 0.07)</td>\n",
       "      <td>0.516524</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>(1, 0.08)</td>\n",
       "      <td>0.516309</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>(2, 0.03)</td>\n",
       "      <td>0.519511</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>(2, 0.04)</td>\n",
       "      <td>0.514189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>(2, 0.05)</td>\n",
       "      <td>0.510870</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>(2, 0.06)</td>\n",
       "      <td>0.505869</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>(2, 0.07)</td>\n",
       "      <td>0.504169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>(2, 0.08)</td>\n",
       "      <td>0.500612</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>(3, 0.03)</td>\n",
       "      <td>0.508103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>(3, 0.04)</td>\n",
       "      <td>0.504189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>(3, 0.05)</td>\n",
       "      <td>0.501073</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>(3, 0.06)</td>\n",
       "      <td>0.501577</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>(3, 0.07)</td>\n",
       "      <td>0.499579</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>(3, 0.08)</td>\n",
       "      <td>0.498583</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>(4, 0.03)</td>\n",
       "      <td>0.500145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>(4, 0.04)</td>\n",
       "      <td>0.497244</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>(4, 0.05)</td>\n",
       "      <td>0.499040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>(4, 0.06)</td>\n",
       "      <td>0.496901</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>(4, 0.07)</td>\n",
       "      <td>0.499214</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>(4, 0.08)</td>\n",
       "      <td>0.496475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>(5, 0.03)</td>\n",
       "      <td>0.502256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>(5, 0.04)</td>\n",
       "      <td>0.499437</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>(5, 0.05)</td>\n",
       "      <td>0.504923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>(5, 0.06)</td>\n",
       "      <td>0.500364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>(5, 0.07)</td>\n",
       "      <td>0.498278</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>(5, 0.08)</td>\n",
       "      <td>0.500113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>(6, 0.03)</td>\n",
       "      <td>0.501923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>(6, 0.04)</td>\n",
       "      <td>0.498743</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>(6, 0.05)</td>\n",
       "      <td>0.494848</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>(6, 0.06)</td>\n",
       "      <td>0.503576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>(6, 0.07)</td>\n",
       "      <td>0.495027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>(6, 0.08)</td>\n",
       "      <td>0.497663</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>(7, 0.03)</td>\n",
       "      <td>0.502909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>(7, 0.04)</td>\n",
       "      <td>0.495268</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>(7, 0.05)</td>\n",
       "      <td>0.501645</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>(7, 0.06)</td>\n",
       "      <td>0.500908</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>(7, 0.07)</td>\n",
       "      <td>0.498481</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>(7, 0.08)</td>\n",
       "      <td>0.494393</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>(8, 0.03)</td>\n",
       "      <td>0.497831</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>(8, 0.04)</td>\n",
       "      <td>0.497297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>(8, 0.05)</td>\n",
       "      <td>0.498192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>(8, 0.06)</td>\n",
       "      <td>0.494761</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>(8, 0.07)</td>\n",
       "      <td>0.496916</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>(8, 0.08)</td>\n",
       "      <td>0.497891</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>(9, 0.03)</td>\n",
       "      <td>0.501196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>(9, 0.04)</td>\n",
       "      <td>0.497448</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>(9, 0.05)</td>\n",
       "      <td>0.493936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>(9, 0.06)</td>\n",
       "      <td>0.493606</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>(9, 0.07)</td>\n",
       "      <td>0.496570</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>(9, 0.08)</td>\n",
       "      <td>0.496860</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       params        r2\n",
       "0   (1, 0.03)  0.523491\n",
       "1   (1, 0.04)  0.523231\n",
       "2   (1, 0.05)  0.520601\n",
       "3   (1, 0.06)  0.518823\n",
       "4   (1, 0.07)  0.516524\n",
       "5   (1, 0.08)  0.516309\n",
       "6   (2, 0.03)  0.519511\n",
       "7   (2, 0.04)  0.514189\n",
       "8   (2, 0.05)  0.510870\n",
       "9   (2, 0.06)  0.505869\n",
       "10  (2, 0.07)  0.504169\n",
       "11  (2, 0.08)  0.500612\n",
       "12  (3, 0.03)  0.508103\n",
       "13  (3, 0.04)  0.504189\n",
       "14  (3, 0.05)  0.501073\n",
       "15  (3, 0.06)  0.501577\n",
       "16  (3, 0.07)  0.499579\n",
       "17  (3, 0.08)  0.498583\n",
       "18  (4, 0.03)  0.500145\n",
       "19  (4, 0.04)  0.497244\n",
       "20  (4, 0.05)  0.499040\n",
       "21  (4, 0.06)  0.496901\n",
       "22  (4, 0.07)  0.499214\n",
       "23  (4, 0.08)  0.496475\n",
       "24  (5, 0.03)  0.502256\n",
       "25  (5, 0.04)  0.499437\n",
       "26  (5, 0.05)  0.504923\n",
       "27  (5, 0.06)  0.500364\n",
       "28  (5, 0.07)  0.498278\n",
       "29  (5, 0.08)  0.500113\n",
       "30  (6, 0.03)  0.501923\n",
       "31  (6, 0.04)  0.498743\n",
       "32  (6, 0.05)  0.494848\n",
       "33  (6, 0.06)  0.503576\n",
       "34  (6, 0.07)  0.495027\n",
       "35  (6, 0.08)  0.497663\n",
       "36  (7, 0.03)  0.502909\n",
       "37  (7, 0.04)  0.495268\n",
       "38  (7, 0.05)  0.501645\n",
       "39  (7, 0.06)  0.500908\n",
       "40  (7, 0.07)  0.498481\n",
       "41  (7, 0.08)  0.494393\n",
       "42  (8, 0.03)  0.497831\n",
       "43  (8, 0.04)  0.497297\n",
       "44  (8, 0.05)  0.498192\n",
       "45  (8, 0.06)  0.494761\n",
       "46  (8, 0.07)  0.496916\n",
       "47  (8, 0.08)  0.497891\n",
       "48  (9, 0.03)  0.501196\n",
       "49  (9, 0.04)  0.497448\n",
       "50  (9, 0.05)  0.493936\n",
       "51  (9, 0.06)  0.493606\n",
       "52  (9, 0.07)  0.496570\n",
       "53  (9, 0.08)  0.496860"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb = pd.DataFrame(list(zip(params, r2)), columns =['params', 'r2'])\n",
    "xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "8b163b33",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = np.mean( np.array([ model2(X).detach().numpy().flatten(), model.predict(X) ]), axis=0 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "b06f1058",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5722461616302965"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r2_score(y_test, model.predict(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "eb2f4a13",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([353.94666, 348.92538, 277.738  , 320.78235, 359.33618, 353.0382 ,\n",
       "       386.13763, 216.6109 , 274.40436, 271.8137 , 384.7299 , 424.28333,\n",
       "       422.5855 , 377.6869 , 384.96637, 333.08768, 303.48062, 392.3758 ,\n",
       "       437.54016, 311.47696, 297.18857, 337.53143, 278.37848, 395.42105,\n",
       "       267.13434, 288.36646, 384.24115, 340.2953 , 372.06427, 428.0089 ,\n",
       "       335.58264, 335.342  , 380.8922 , 328.6947 , 428.77374, 306.6346 ,\n",
       "       402.1638 , 308.71243, 392.58234, 336.66583, 404.05518, 380.8922 ,\n",
       "       282.18964, 296.92126, 386.2401 , 421.7724 , 316.34372, 406.56763,\n",
       "       357.77533, 409.98975, 296.8744 , 383.26422, 321.62006, 289.99567,\n",
       "       392.80322, 233.72089, 441.32166, 352.04346, 308.06406, 388.92972,\n",
       "       242.63597, 335.43018, 353.51404, 278.88757, 335.42047, 380.60223,\n",
       "       355.32336, 371.696  , 374.633  , 359.693  , 340.68958, 328.21692,\n",
       "       398.20288, 403.3898 , 276.4377 , 328.81512, 357.14282, 316.52673,\n",
       "       335.91455, 346.8915 , 420.49683, 364.1969 , 326.66235, 381.26453,\n",
       "       359.09888, 382.40887, 310.10944, 434.91974, 211.27747, 383.16028,\n",
       "       394.06647, 234.41336, 373.6058 , 346.64563, 353.2285 , 347.2433 ,\n",
       "       370.49683, 361.813  , 403.99103, 320.80994, 401.91495, 333.24905,\n",
       "       330.24548, 393.82413, 349.11203, 330.22815, 342.70087, 360.95682,\n",
       "       401.06216, 412.567  , 355.39545, 235.21843, 277.5203 , 412.42578,\n",
       "       385.94257, 355.5729 , 406.33023, 365.65845, 335.42334, 403.6537 ,\n",
       "       384.53598, 289.34906, 344.63913, 383.74838, 193.70932, 413.72552,\n",
       "       353.03323, 383.9853 , 315.33484, 309.58258, 306.9024 , 358.59808],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "709f6b5f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>353.946655</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>348.925385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>277.738007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>320.782349</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>359.336182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127</th>\n",
       "      <td>383.985291</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128</th>\n",
       "      <td>315.334839</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>129</th>\n",
       "      <td>309.582581</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130</th>\n",
       "      <td>306.902405</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131</th>\n",
       "      <td>358.598083</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>132 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              0\n",
       "0    353.946655\n",
       "1    348.925385\n",
       "2    277.738007\n",
       "3    320.782349\n",
       "4    359.336182\n",
       "..          ...\n",
       "127  383.985291\n",
       "128  315.334839\n",
       "129  309.582581\n",
       "130  306.902405\n",
       "131  358.598083\n",
       "\n",
       "[132 rows x 1 columns]"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out = pd.DataFrame(y_pred)\n",
    "out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "95fe1b6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "out = out.rename(columns={0: 'price'})\n",
    "out.index.names = ['id']\n",
    "out.to_csv('solution.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b624bd0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
